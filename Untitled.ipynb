{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Required libraires for the project\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "text_list=[]\n",
    "label_list=[]\n",
    "df = pd.DataFrame(columns=['Text','Label'])\n",
    "count=0\n",
    "for root, dirs, files in os.walk(\"/Users/prashanthimallijula/Documents/EECS738/project3/lingspam_public/bare/\"):\n",
    "    #os.path.join(root)\n",
    "    for  root, dirs, files in os.walk(root):\n",
    "            for file in files:\n",
    "                if count > 0:\n",
    "                    f = open(root+\"/\"+file, \"r\",encoding=\"utf8\", errors='ignore')\n",
    "                    text= f.read()\n",
    "                    if (file[0:4]==\"spms\"):\n",
    "                        lable= \"spam\"\n",
    "                    else:\n",
    "                        lable= \"not_spam\"\n",
    "                    f.close()\n",
    "                    text_list.append(text[8:])\n",
    "                    label_list.append(lable)\n",
    "\n",
    "            count=count+1\n",
    "df['Text']=text_list\n",
    "df['Label']=label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job posting - apple-iss research center\\n\\nco...</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nlang classification grimes , joseph e . a...</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query : letter frequencies for text identific...</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>risk\\n\\na colleague and i are researching the...</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request book information\\n\\nearlier this morn...</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Label\n",
       "0   job posting - apple-iss research center\\n\\nco...  not_spam\n",
       "1   \\n\\nlang classification grimes , joseph e . a...  not_spam\n",
       "2   query : letter frequencies for text identific...  not_spam\n",
       "3   risk\\n\\na colleague and i are researching the...  not_spam\n",
       "4   request book information\\n\\nearlier this morn...  not_spam"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not_spam', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "df['Text'].dropna(inplace=True)\n",
    "df['tokenized_text'] =df['Text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [job, posting, -, apple-iss, research, center,...\n",
       "1    [lang, classification, grimes, ,, joseph, e, ....\n",
       "2    [query, :, letter, frequencies, for, text, ide...\n",
       "3    [risk, a, colleague, and, i, are, researching,...\n",
       "4    [request, book, information, earlier, this, mo...\n",
       "Name: tokenized_text, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/prashanthimallijula/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Check stop words and special characters\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "special=['!','@','#','$','%','^','&','*','(',')',':','<','>',',','.',';','{','}','|','_','-','+','=','`','~',\"--\",\"'\",'\"','[',']','\\n','/','\\\\']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/prashanthimallijula/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Remove speacial characters\n",
    "#Check stop words and special characters\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "special=['!','@','#','$','%','^','&','*','(',')',':','<','>',',','.',';','{','}','|','_','-','+','=','`','~',\"--\",\"'\",'\"','[',']','\\n','/','\\\\']\n",
    "for item  in df['tokenized_text']:\n",
    "    item_new=[]\n",
    "    for word in item:\n",
    "        word=str(word)\n",
    "        if (word in special) and (word.isalpha() == False):\n",
    "            item.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job posting - apple-iss research center\\n\\nco...</td>\n",
       "      <td>not_spam</td>\n",
       "      <td>[job, posting, apple-iss, research, center, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nlang classification grimes , joseph e . a...</td>\n",
       "      <td>not_spam</td>\n",
       "      <td>[lang, classification, grimes, joseph, e, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query : letter frequencies for text identific...</td>\n",
       "      <td>not_spam</td>\n",
       "      <td>[query, letter, frequencies, for, text, identi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>risk\\n\\na colleague and i are researching the...</td>\n",
       "      <td>not_spam</td>\n",
       "      <td>[risk, a, colleague, and, i, are, researching,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request book information\\n\\nearlier this morn...</td>\n",
       "      <td>not_spam</td>\n",
       "      <td>[request, book, information, earlier, this, mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Label  \\\n",
       "0   job posting - apple-iss research center\\n\\nco...  not_spam   \n",
       "1   \\n\\nlang classification grimes , joseph e . a...  not_spam   \n",
       "2   query : letter frequencies for text identific...  not_spam   \n",
       "3   risk\\n\\na colleague and i are researching the...  not_spam   \n",
       "4   request book information\\n\\nearlier this morn...  not_spam   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [job, posting, apple-iss, research, center, co...  \n",
       "1  [lang, classification, grimes, joseph, e, and,...  \n",
       "2  [query, letter, frequencies, for, text, identi...  \n",
       "3  [risk, a, colleague, and, i, are, researching,...  \n",
       "4  [request, book, information, earlier, this, mo...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sum',\n",
       " 'progressive',\n",
       " 'with',\n",
       " 'future',\n",
       " 'time',\n",
       " 'reference',\n",
       " 'content',\n",
       " 'length',\n",
       " '6465',\n",
       " 'some',\n",
       " 'time',\n",
       " 'ago',\n",
       " 'i',\n",
       " 'posted',\n",
       " 'a',\n",
       " 'query',\n",
       " 'concerning',\n",
       " 'the',\n",
       " 'possible',\n",
       " 'existence',\n",
       " 'of',\n",
       " 'languages',\n",
       " 'in',\n",
       " 'which',\n",
       " 'the',\n",
       " 'morpheme',\n",
       " 'expressing',\n",
       " 'the',\n",
       " 'notion',\n",
       " 'of',\n",
       " '``',\n",
       " 'progressive',\n",
       " '``',\n",
       " 'may',\n",
       " 'be',\n",
       " 'used',\n",
       " 'with',\n",
       " 'future',\n",
       " 'time',\n",
       " 'reference',\n",
       " 'as',\n",
       " 'in',\n",
       " 'english',\n",
       " 'i',\n",
       " 'am',\n",
       " 'leaving',\n",
       " 'tomorrow',\n",
       " 'the',\n",
       " 'coexistence',\n",
       " 'of',\n",
       " 'progressive',\n",
       " 'and',\n",
       " 'a',\n",
       " 'future',\n",
       " 'time',\n",
       " 'adverbial',\n",
       " 'is',\n",
       " 'the',\n",
       " 'decisive',\n",
       " 'factor',\n",
       " 'i',\n",
       " 'started',\n",
       " 'from',\n",
       " 'a',\n",
       " 'very',\n",
       " 'scanty',\n",
       " 'piece',\n",
       " 'of',\n",
       " 'knowledge',\n",
       " 'besides',\n",
       " 'english',\n",
       " 'i',\n",
       " 'only',\n",
       " 'know',\n",
       " 'of',\n",
       " 'icelandic',\n",
       " 'quoted',\n",
       " 'in',\n",
       " 'a',\n",
       " 'paper',\n",
       " 'by',\n",
       " 'karen',\n",
       " 'ebert',\n",
       " 'that',\n",
       " 'will',\n",
       " 'appear',\n",
       " 'in',\n",
       " 'a',\n",
       " 'volume',\n",
       " 'on',\n",
       " 'tense',\n",
       " 'and',\n",
       " 'aspect',\n",
       " 'and',\n",
       " 'possibly',\n",
       " 'kinyarwanda',\n",
       " 'but',\n",
       " 'i',\n",
       " 'need',\n",
       " 'more',\n",
       " 'data',\n",
       " 'concerning',\n",
       " 'this',\n",
       " 'language',\n",
       " 'as',\n",
       " 'i',\n",
       " 'suspected',\n",
       " 'this',\n",
       " 'feature',\n",
       " 'seems',\n",
       " 'to',\n",
       " 'be',\n",
       " 'very',\n",
       " 'rare',\n",
       " 'i',\n",
       " 'got',\n",
       " 'only',\n",
       " 'two',\n",
       " 'answers',\n",
       " 'the',\n",
       " 'first',\n",
       " 'one',\n",
       " 'is',\n",
       " 'from',\n",
       " 'john',\n",
       " 'koontz',\n",
       " 'koontz',\n",
       " 'alpha',\n",
       " 'bldr',\n",
       " 'nist',\n",
       " 'gov',\n",
       " 'since',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'particularly',\n",
       " 'long',\n",
       " 'i',\n",
       " 'reproduce',\n",
       " 'it',\n",
       " 'entirely',\n",
       " 'the',\n",
       " 'dhegiha',\n",
       " 'branch',\n",
       " 'of',\n",
       " 'mississippi',\n",
       " 'valley',\n",
       " 'siouan',\n",
       " 'all',\n",
       " 'form',\n",
       " 'progressives',\n",
       " 'by',\n",
       " 'pairing',\n",
       " 'the',\n",
       " 'simple',\n",
       " 'verb',\n",
       " 'with',\n",
       " 'a',\n",
       " 'positional',\n",
       " 'auxiliary',\n",
       " 'and',\n",
       " 'omitting',\n",
       " 'the',\n",
       " 'plural',\n",
       " 'proximate',\n",
       " 'marker',\n",
       " 'that',\n",
       " 'otherwise',\n",
       " 'occurs',\n",
       " 'in',\n",
       " 'the',\n",
       " 'plural',\n",
       " 'forms',\n",
       " 'and',\n",
       " 'the',\n",
       " 'third',\n",
       " 'person',\n",
       " 'singular',\n",
       " 'proximate',\n",
       " 'dhatha',\n",
       " 'i',\n",
       " 'he',\n",
       " 'ate',\n",
       " 'eats',\n",
       " 'dhatha',\n",
       " 'i',\n",
       " 'they',\n",
       " 'ate',\n",
       " 'eat',\n",
       " 'dhathe',\n",
       " 'he',\n",
       " 'obv',\n",
       " 'ate',\n",
       " 'eats',\n",
       " 'dhathe',\n",
       " 'akha',\n",
       " 'he',\n",
       " 'is',\n",
       " 'eating',\n",
       " 'dhathe',\n",
       " 'ama',\n",
       " 'they',\n",
       " 'are',\n",
       " 'eating',\n",
       " 'the',\n",
       " 'usual',\n",
       " 'reading',\n",
       " 'of',\n",
       " 'the',\n",
       " 'simple',\n",
       " 'form',\n",
       " 'is',\n",
       " 'past',\n",
       " 'aorist',\n",
       " 'there',\n",
       " 'are',\n",
       " 'special',\n",
       " 'auxiliary',\n",
       " 'and',\n",
       " 'or',\n",
       " 'enclitic',\n",
       " 'constructions',\n",
       " 'for',\n",
       " 'habitual',\n",
       " 'the',\n",
       " 'future',\n",
       " 'is',\n",
       " 'formed',\n",
       " 'with',\n",
       " 'the',\n",
       " 'enclitic',\n",
       " 'tte',\n",
       " 'which',\n",
       " 'requires',\n",
       " 'the',\n",
       " 'auxiliary',\n",
       " 'following',\n",
       " 'it',\n",
       " 'dhathe',\n",
       " 'tta',\n",
       " 'akha',\n",
       " 'he',\n",
       " 'will',\n",
       " 'eat',\n",
       " 'dhathe',\n",
       " 'tta',\n",
       " 'ama',\n",
       " 'they',\n",
       " 'will',\n",
       " 'eat',\n",
       " 'the',\n",
       " 'future',\n",
       " 'without',\n",
       " 'the',\n",
       " 'auxiliary',\n",
       " 'expresses',\n",
       " 'polite',\n",
       " 'requests',\n",
       " 'and',\n",
       " 'there',\n",
       " 'is',\n",
       " 'also',\n",
       " 'a',\n",
       " 'form',\n",
       " 'tta',\n",
       " 'i',\n",
       " 'the',\n",
       " 'no',\n",
       " 'auxiliary',\n",
       " 'basically',\n",
       " 'the',\n",
       " 'evidential',\n",
       " 'of',\n",
       " 'the',\n",
       " 'future',\n",
       " 'that',\n",
       " 'has',\n",
       " 'the',\n",
       " 'reading',\n",
       " 'shall',\n",
       " 'surely',\n",
       " 'dhathe',\n",
       " 'tta',\n",
       " 'i',\n",
       " 'the',\n",
       " 'he',\n",
       " 'they',\n",
       " 'shall',\n",
       " 'surely',\n",
       " 'eat',\n",
       " 'note',\n",
       " 'also',\n",
       " 'dhatha',\n",
       " 'bi',\n",
       " 'ama',\n",
       " 'they',\n",
       " 'say',\n",
       " 'that',\n",
       " 'he',\n",
       " 'ate',\n",
       " 'eats',\n",
       " 'not',\n",
       " 'the',\n",
       " 'same',\n",
       " 'ama',\n",
       " 'i',\n",
       " 'believe',\n",
       " 'dhatha',\n",
       " 'i',\n",
       " 'the',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'that',\n",
       " 'he',\n",
       " 'ate',\n",
       " 'eats',\n",
       " 'john',\n",
       " 'koontz',\n",
       " 'answering',\n",
       " 'a',\n",
       " 'further',\n",
       " 'request',\n",
       " 'of',\n",
       " 'clarification',\n",
       " 'koontz',\n",
       " 'kindly',\n",
       " 'added',\n",
       " 'the',\n",
       " 'following',\n",
       " 'the',\n",
       " 'letter',\n",
       " 'b',\n",
       " 'presumably',\n",
       " 'stands',\n",
       " 'for',\n",
       " 'my',\n",
       " 'syrname',\n",
       " 'the',\n",
       " 'dhegiha',\n",
       " 'branch',\n",
       " 'of',\n",
       " 'mississippi',\n",
       " 'valley',\n",
       " 'siouan',\n",
       " 'all',\n",
       " 'form',\n",
       " 'progressives',\n",
       " 'by',\n",
       " 'pairing',\n",
       " 'the',\n",
       " 'simple',\n",
       " 'verb',\n",
       " 'with',\n",
       " 'a',\n",
       " 'positional',\n",
       " 'auxiliary',\n",
       " 'and',\n",
       " 'omitting',\n",
       " 'the',\n",
       " 'plural',\n",
       " 'proximate',\n",
       " 'marker',\n",
       " 'that',\n",
       " 'otherwise',\n",
       " 'occurs',\n",
       " 'in',\n",
       " 'the',\n",
       " 'plural',\n",
       " 'forms',\n",
       " 'and',\n",
       " 'the',\n",
       " 'third',\n",
       " 'person',\n",
       " 'singular',\n",
       " 'proximate',\n",
       " 'dhatha',\n",
       " 'i',\n",
       " 'he',\n",
       " 'ate',\n",
       " 'eats',\n",
       " 'dhatha',\n",
       " 'i',\n",
       " 'they',\n",
       " 'ate',\n",
       " 'eat',\n",
       " 'dhathe',\n",
       " 'he',\n",
       " 'obv',\n",
       " 'ate',\n",
       " 'eats',\n",
       " 'dhathe',\n",
       " 'akha',\n",
       " 'he',\n",
       " 'is',\n",
       " 'eating',\n",
       " 'dhathe',\n",
       " 'ama',\n",
       " 'they',\n",
       " 'are',\n",
       " 'eating',\n",
       " 'b',\n",
       " 'why',\n",
       " 'are',\n",
       " 'there',\n",
       " 'two',\n",
       " 'forms',\n",
       " 'akha',\n",
       " 'and',\n",
       " 'ama',\n",
       " '?',\n",
       " 'these',\n",
       " 'auxiliaries',\n",
       " 'are',\n",
       " 'identical',\n",
       " 'to',\n",
       " 'the',\n",
       " 'definite',\n",
       " 'articles',\n",
       " 'and',\n",
       " 'like',\n",
       " 'them',\n",
       " 'code',\n",
       " 'the',\n",
       " 'shape',\n",
       " 'posture',\n",
       " 'motion',\n",
       " 'of',\n",
       " 'the',\n",
       " 'subject',\n",
       " 'historically',\n",
       " 'there',\n",
       " 'are',\n",
       " 'derived',\n",
       " 'from',\n",
       " 'positional',\n",
       " 'verbs',\n",
       " 'and',\n",
       " 'particles',\n",
       " 'akha',\n",
       " 'is',\n",
       " 'the',\n",
       " 'singular',\n",
       " 'motionless',\n",
       " 'proximate',\n",
       " 'form',\n",
       " 'ama',\n",
       " 'is',\n",
       " 'the',\n",
       " 'plural',\n",
       " 'or',\n",
       " 'singular',\n",
       " 'moving',\n",
       " 'proximate',\n",
       " 'form',\n",
       " 'other',\n",
       " 'forms',\n",
       " 'are',\n",
       " 'used',\n",
       " 'in',\n",
       " 'the',\n",
       " 'first',\n",
       " 'and',\n",
       " 'second',\n",
       " 'persons',\n",
       " 'generally',\n",
       " 'derived',\n",
       " 'from',\n",
       " 'the',\n",
       " 'sitting',\n",
       " 'article',\n",
       " 'auxiliary',\n",
       " 'e',\n",
       " 'g',\n",
       " 'mi',\n",
       " 'khe',\n",
       " 'i',\n",
       " 'the',\n",
       " 'sitting',\n",
       " 'ni',\n",
       " 'khe',\n",
       " 'you',\n",
       " 'the',\n",
       " 'sitting',\n",
       " 'the',\n",
       " 'stem',\n",
       " 'is',\n",
       " 'dhi',\n",
       " 'khe',\n",
       " 'he',\n",
       " 'the',\n",
       " 'sitting',\n",
       " 'the',\n",
       " 'usual',\n",
       " 'reading',\n",
       " 'of',\n",
       " 'the',\n",
       " 'simple',\n",
       " 'form',\n",
       " 'is',\n",
       " 'past',\n",
       " 'aorist',\n",
       " 'there',\n",
       " 'are',\n",
       " 'special',\n",
       " 'auxiliary',\n",
       " 'and',\n",
       " 'or',\n",
       " 'enclitic',\n",
       " 'constructions',\n",
       " 'for',\n",
       " 'habitual',\n",
       " 'b',\n",
       " 'your',\n",
       " 'gloss',\n",
       " 'indicates',\n",
       " 'indicates',\n",
       " 'present',\n",
       " 'meaning',\n",
       " 'non',\n",
       " 'only',\n",
       " 'past',\n",
       " 'aorist',\n",
       " 'b',\n",
       " 'meaning',\n",
       " 'a',\n",
       " 'present',\n",
       " 'non-progressive',\n",
       " 'reading',\n",
       " 'is',\n",
       " 'possible',\n",
       " 'in',\n",
       " 'appropriate',\n",
       " 'contexts',\n",
       " 'i',\n",
       " 'believe',\n",
       " 'such',\n",
       " 'forms',\n",
       " 'are',\n",
       " 'essentially',\n",
       " 'nomic',\n",
       " 'the',\n",
       " 'future',\n",
       " 'is',\n",
       " 'formed',\n",
       " 'with',\n",
       " 'the',\n",
       " 'enclitic',\n",
       " 'tte',\n",
       " 'which',\n",
       " 'requires',\n",
       " 'the',\n",
       " 'auxiliary',\n",
       " 'following',\n",
       " 'it',\n",
       " 'dhathe',\n",
       " 'tta',\n",
       " 'akha',\n",
       " 'he',\n",
       " 'will',\n",
       " 'eat',\n",
       " 'dhathe',\n",
       " 'tta',\n",
       " 'ama',\n",
       " 'they',\n",
       " 'will',\n",
       " 'eat',\n",
       " 'b',\n",
       " 'does',\n",
       " 'it',\n",
       " 'have',\n",
       " 'progressive',\n",
       " 'and',\n",
       " 'future',\n",
       " 'meaning',\n",
       " 'or',\n",
       " 'only',\n",
       " 'future',\n",
       " '?',\n",
       " 'no',\n",
       " 'trace',\n",
       " 'at',\n",
       " 'all',\n",
       " 'of',\n",
       " 'progressive',\n",
       " 'reading',\n",
       " 'that',\n",
       " 'i',\n",
       " 'have',\n",
       " 'detected',\n",
       " 'the',\n",
       " 'forms',\n",
       " 'without',\n",
       " 'the',\n",
       " 'auxiliary',\n",
       " 'are',\n",
       " 'limited',\n",
       " 'to',\n",
       " 'those',\n",
       " 'mentioned',\n",
       " 'i',\n",
       " 'e',\n",
       " 'the',\n",
       " 'future',\n",
       " 'of',\n",
       " 'surity',\n",
       " 'with',\n",
       " 'the',\n",
       " 'appended',\n",
       " 'and',\n",
       " 'the',\n",
       " 'future',\n",
       " 'of',\n",
       " 'polite',\n",
       " 'requests',\n",
       " 'used',\n",
       " 'without',\n",
       " 'further',\n",
       " 'marking',\n",
       " 'in',\n",
       " 'the',\n",
       " 'second',\n",
       " 'person',\n",
       " 'the',\n",
       " 'future',\n",
       " 'without',\n",
       " 'the',\n",
       " 'auxiliary',\n",
       " 'expresses',\n",
       " 'polite',\n",
       " 'requests',\n",
       " 'and',\n",
       " 'there',\n",
       " 'is',\n",
       " 'also',\n",
       " 'a',\n",
       " 'form',\n",
       " 'tta',\n",
       " 'i',\n",
       " 'the',\n",
       " 'no',\n",
       " 'auxiliary',\n",
       " 'basically',\n",
       " 'the',\n",
       " 'evidential',\n",
       " 'of',\n",
       " 'the',\n",
       " 'future',\n",
       " 'that',\n",
       " 'has',\n",
       " 'the',\n",
       " 'reading',\n",
       " 'shall',\n",
       " 'surely',\n",
       " 'dhathe',\n",
       " 'tta',\n",
       " 'i',\n",
       " 'the',\n",
       " 'he',\n",
       " 'they',\n",
       " 'shall',\n",
       " 'surely',\n",
       " 'eat',\n",
       " 'note',\n",
       " 'also',\n",
       " 'dhatha',\n",
       " 'bi',\n",
       " 'ama',\n",
       " 'they',\n",
       " 'say',\n",
       " 'that',\n",
       " 'he',\n",
       " 'ate',\n",
       " 'eats',\n",
       " 'not',\n",
       " 'the',\n",
       " 'same',\n",
       " 'ama',\n",
       " 'i',\n",
       " 'believe',\n",
       " 'dhatha',\n",
       " 'i',\n",
       " 'the',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'that',\n",
       " 'he',\n",
       " 'ate',\n",
       " 'eats',\n",
       " 'john',\n",
       " 'koontz',\n",
       " 'similar',\n",
       " 'patterns',\n",
       " 'occur',\n",
       " 'in',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " 'dhegiha',\n",
       " 'languages',\n",
       " 'i',\n",
       " 'e',\n",
       " 'omaha',\n",
       " 'ponca',\n",
       " 'osage',\n",
       " 'kansa',\n",
       " 'kaw',\n",
       " 'and',\n",
       " 'quapaw',\n",
       " 'the',\n",
       " 'second',\n",
       " 'answer',\n",
       " 'is',\n",
       " 'from',\n",
       " 'lars',\n",
       " 'anders',\n",
       " 'kulbrandstad',\n",
       " 'larsanders',\n",
       " 'kulbrandstad',\n",
       " 'hamarlh',\n",
       " 'no',\n",
       " 'unfortunately',\n",
       " 'there',\n",
       " 'are',\n",
       " 'some',\n",
       " 'misterious',\n",
       " 'characters',\n",
       " 'but',\n",
       " 'the',\n",
       " 'content',\n",
       " 'is',\n",
       " 'sufficiently',\n",
       " 'clear',\n",
       " 'there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'fullfledged',\n",
       " 'progressive',\n",
       " 'construction',\n",
       " 'in',\n",
       " 'norwegian',\n",
       " 'but',\n",
       " 'we',\n",
       " 'have',\n",
       " 'something',\n",
       " 'that',\n",
       " 'still',\n",
       " 'might',\n",
       " 'be',\n",
       " 'of',\n",
       " 'interest',\n",
       " 'to',\n",
       " 'you',\n",
       " 'dialects',\n",
       " 'in',\n",
       " 'the',\n",
       " 'south-eastern',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'country',\n",
       " 'have',\n",
       " 'a',\n",
       " 'future',\n",
       " 'construction',\n",
       " 'consisting',\n",
       " 'of',\n",
       " 'the',\n",
       " 'auxilliary',\n",
       " '``',\n",
       " 'bli',\n",
       " '``',\n",
       " 'literally',\n",
       " '3d',\n",
       " '``',\n",
       " 'get',\n",
       " 'become',\n",
       " '``',\n",
       " 'in',\n",
       " 'the',\n",
       " 'present',\n",
       " 'tense',\n",
       " 'present',\n",
       " 'participle',\n",
       " 'of',\n",
       " 'the',\n",
       " 'main',\n",
       " 'verb',\n",
       " 'the',\n",
       " 'sentence',\n",
       " 'corresponding',\n",
       " 'to',\n",
       " '``',\n",
       " 'i',\n",
       " 'will',\n",
       " 'be',\n",
       " 'going',\n",
       " 'to',\n",
       " 'oslo',\n",
       " 'tomorrow',\n",
       " '``',\n",
       " 'would',\n",
       " 'be',\n",
       " '``',\n",
       " 'je',\n",
       " 'blir',\n",
       " 'draens',\n",
       " '3d',\n",
       " '``',\n",
       " 'i',\n",
       " 'get',\n",
       " 'become',\n",
       " 'going',\n",
       " '``',\n",
       " 'tel',\n",
       " 'oslo',\n",
       " 'i',\n",
       " 'm',\n",
       " 'e5r',\n",
       " 'e5',\n",
       " '``',\n",
       " '=',\n",
       " '=',\n",
       " '=',\n",
       " '=',\n",
       " '=',\n",
       " '=',\n",
       " 'i',\n",
       " 'hope',\n",
       " 'this',\n",
       " 'may',\n",
       " 'be',\n",
       " 'of',\n",
       " 'some',\n",
       " 'interest',\n",
       " 'to',\n",
       " 'somebody',\n",
       " 'or',\n",
       " 'maybe',\n",
       " 'stimulate',\n",
       " 'other',\n",
       " 'people',\n",
       " 'to',\n",
       " 'provide',\n",
       " 'further',\n",
       " 'information',\n",
       " 'on',\n",
       " 'this',\n",
       " 'matter',\n",
       " 'i',\n",
       " 'am',\n",
       " 'still',\n",
       " 'eager',\n",
       " 'to',\n",
       " 'receive',\n",
       " 'new',\n",
       " 'input',\n",
       " 'thanks',\n",
       " 'to',\n",
       " 'those',\n",
       " 'who',\n",
       " 'responded',\n",
       " 'best',\n",
       " 'pm',\n",
       " 'pier',\n",
       " 'marco',\n",
       " 'bertinetto',\n",
       " 'scuola',\n",
       " 'normale',\n",
       " 'superiore',\n",
       " 'p',\n",
       " 'za',\n",
       " 'dei',\n",
       " 'cavalieri',\n",
       " '7',\n",
       " 'i-56126',\n",
       " 'pisa',\n",
       " 'tel',\n",
       " '39',\n",
       " '0',\n",
       " '50',\n",
       " '509111',\n",
       " 'fax',\n",
       " '39',\n",
       " '0',\n",
       " '50',\n",
       " '563513',\n",
       " '-',\n",
       " 'nb',\n",
       " 'alternative',\n",
       " 'email',\n",
       " 'addresses',\n",
       " 'bertinet',\n",
       " 'sns',\n",
       " 'it',\n",
       " '/',\n",
       " 'bertinetto',\n",
       " 'sns',\n",
       " 'it',\n",
       " '/']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_text'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
